{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3436fe-a8bd-44eb-8697-6f160839f0ff",
   "metadata": {},
   "source": [
    "# BASIC PRE-PROCESSING - {\"BLACK FRIDAY SALES\" DATASET}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2af72-cda7-4524-a75e-716950556796",
   "metadata": {},
   "source": [
    "## 1. Import Modules and Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451c3cef-ea2f-420d-8181-541cb2d2ff51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d395bd-1568-47a6-a0c6-ffaf64da18a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PD Options\n",
    "\n",
    "pd.set_option('display.min_rows', 5)\n",
    "pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4ee4d-f713-4c3f-8fd5-3d35c19512f1",
   "metadata": {},
   "source": [
    "## 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34239b88-5294-4087-880b-5b4b94a34e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('bfs_train.csv')\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feab842-96b6-4a55-aa17-e8f541dbd76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   User_ID                     550068 non-null  int64  \n",
      " 1   Product_ID                  550068 non-null  object \n",
      " 2   Gender                      550068 non-null  object \n",
      " 3   Age                         550068 non-null  object \n",
      " 4   Occupation                  550068 non-null  int64  \n",
      " 5   City_Category               550068 non-null  object \n",
      " 6   Stay_In_Current_City_Years  550068 non-null  object \n",
      " 7   Marital_Status              550068 non-null  int64  \n",
      " 8   Product_Category_1          550068 non-null  int64  \n",
      " 9   Product_Category_2          376430 non-null  float64\n",
      " 10  Product_Category_3          166821 non-null  float64\n",
      " 11  Purchase                    550068 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 50.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de98e022-26bc-4e0c-a551-2e5e8ff8429b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981d4f9-18ca-4eba-bd4d-9a2f9da67e34",
   "metadata": {},
   "source": [
    "## 3. Pre-Processing Level - I, After Data Assessment Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0551fa-91a8-45d5-a792-7cfc767bc4d0",
   "metadata": {},
   "source": [
    "##### Note: Nothing to pre-process here.\n",
    "##### Perform train, validation, test splits on original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e562840-43ef-43e2-a746-4c35bd58ecf9",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 3.1 Splitting Original Data into Train, Validation, and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32dd2de1-3987-4e99-9922-cf7f8e75f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split_REG(fdf, target, vs, ts):\n",
    "    \n",
    "    print(f'Separating X and y from dataframe ----------------------------------------------------------------------------- \\n')\n",
    "    X = fdf.drop(columns=[target])\n",
    "    y = fdf[target]\n",
    " \n",
    "    \n",
    "    print(f'Creating Main[Train + Validation] and Test datasets ----------------------------------------------------------- \\n') \n",
    "    Xmain, Xtest, ymain, ytest = train_test_split(X, y, test_size=ts, random_state=46)   # test size in number of samples\n",
    "        \n",
    "    \n",
    "    print(f'Creating Train and Validation datasets ------------------------------------------------------------------------ \\n') \n",
    "    Xtrain, Xval, ytrain, yval = train_test_split(Xmain, ymain, test_size=vs, random_state=46) # validation size in number of samples\n",
    "        \n",
    "    \n",
    "    print(f'Creating Train, Validation, and Test dataframes as outputs --------------------------------------------------- \\n')\n",
    "    df_train = pd.concat([Xtrain, ytrain], axis=1)\n",
    "    \n",
    "    df_valid = pd.concat([Xval, yval], axis=1)\n",
    "   \n",
    "    df_test = pd.concat([Xtest, ytest], axis=1)\n",
    "    \n",
    "    print(f'Data Splitting Done ... --------------------------------------------------------------------------------------- \\n')\n",
    "        \n",
    "    return df_train, df_valid, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e984f3d2-e681-46ae-a3d3-86568847f0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating X and y from dataframe ----------------------------------------------------------------------------- \n",
      "\n",
      "Creating Main[Train + Validation] and Test datasets ----------------------------------------------------------- \n",
      "\n",
      "Creating Train and Validation datasets ------------------------------------------------------------------------ \n",
      "\n",
      "Creating Train, Validation, and Test dataframes as outputs --------------------------------------------------- \n",
      "\n",
      "Data Splitting Done ... --------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = train_valid_test_split_REG(df, 'Purchase', 100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4a0ae-8844-4c42-95e5-eee6ce0622d0",
   "metadata": {},
   "source": [
    "### 3.2 Saving the Spilt Data into CSV and PKL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb7a64a-da5f-4924-966a-6c0c24cd6388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_valid_test_save_CSV_PKL(tr, va, te):\n",
    "    tr.to_csv('bfs_train_init.csv', index=False)\n",
    "    tr.to_pickle('bfs_train_init.pkl')\n",
    "    \n",
    "    va.to_csv('bfs_valid_init.csv', index=False)\n",
    "    va.to_pickle('bfs_valid_init.pkl')\n",
    "    \n",
    "    te.to_csv('bfs_test_init.csv', index=False)\n",
    "    te.to_pickle('bfs_test_init.pkl')\n",
    "    \n",
    "    print(f'Train, Validation, and Test files created successfully ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e8e18c-1850-4e19-a037-aac293a57ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Validation, and Test files created successfully ...\n"
     ]
    }
   ],
   "source": [
    "train_valid_test_save_CSV_PKL(train, valid, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b32aa4-8a8c-4c62-aac4-2cb990fe1c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
